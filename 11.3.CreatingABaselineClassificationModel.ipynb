{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Fallback-Option: Rechne über dem Iris-Datensatz. \n",
    "# Aber eigentlich interessiert uns ja Titanic:\n",
    "titanic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses Notebook: Kleine Ausarbeitung von MLPC Rezept 11.3. Datensatz laden, skalieren, Logit-Regression anwenden.\n",
    "\n",
    "Zu tun: Alter besser berechnen als stur eine 33.33 einzutragen. Also eignet sich dieses Notebook als Umgebung, um ein kleines Regressions-Projekt zur Alters-Abschätzung einzufügen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datensätze laden\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fallback: Iris\n",
    "\n",
    "Ergebnis des Ladens ist ein ```numpy ndarray```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data \n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Create target vector and feature matrix\n",
    "features, target = iris.data, iris.target\n",
    "\n",
    "# Split into training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Iris, mit np.ndarray\n",
    "features_train_unscaled, features_test_unscaled, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "type(features_train_unscaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic mit pd.read_csv laden\n",
    "\n",
    "Ergebnis ist ein ```DataFrame```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://tinyurl.com/titanic-csv'\n",
    "url = 'https://raw.githubusercontent.com/chrisalbon/simulated_datasets/master/titanic.csv'\n",
    "df = pd.read_csv(url).drop(['Sex', 'Name'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PClassNum'] = df['PClass'].replace([\"1st\", \"2nd\", \"3rd\"], [1.,2.,3.])\n",
    "# alternative Syntax:\n",
    "# df['PClassNum'] = df['PClass'].replace({\"1st\":1, \"2nd\":2, \"3rd\":3, \"*\":2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    711\n",
       "1.0    322\n",
       "2.0    279\n",
       "*        1\n",
       "Name: PClassNum, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prüfen: gibt es noch Werte, die wir nicht ersetzt haben?\n",
    "df.PClassNum.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    711\n",
       "1.0    322\n",
       "2.0    280\n",
       "Name: PClassNum, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aha, in einer Reihe wurde ein \"*\" als Kennzeichen für NaN verwendet.\n",
    "df['PClassNum'] = df['PClassNum'].replace([\"*\"], [2])\n",
    "df.PClassNum.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaanz viele NaN im Attribut Alter!\n",
    "# als baseline möge die Trivial-Strategie genügen (später besser machen)\n",
    "df['Age'] = df['Age'].replace(np.nan, 33.33)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "      <th>PClassNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1st</td>\n",
       "      <td>16.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>3rd</td>\n",
       "      <td>32.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2nd</td>\n",
       "      <td>44.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1st</td>\n",
       "      <td>33.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>3rd</td>\n",
       "      <td>33.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PClass    Age  Survived  SexCode  PClassNum\n",
       "140    1st  16.00         1        1        1.0\n",
       "903    3rd  32.00         1        0        3.0\n",
       "363    2nd  44.00         0        1        2.0\n",
       "199    1st  33.33         0        0        1.0\n",
       "994    3rd  33.33         0        0        3.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train-Test-Split Titanic\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Titanic, mit DataFrame\n",
    "titanic_train, titanic_test = train_test_split(df, test_size=0.2,  random_state=42)\n",
    "titanic_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic\n"
     ]
    }
   ],
   "source": [
    "if titanic:\n",
    "  print(\"Titanic\")  \n",
    "  features_train_unscaled = titanic_train[['PClassNum', 'Age', 'SexCode']].values\n",
    "  features_test_unscaled  = titanic_test [['PClassNum', 'Age', 'SexCode']].values\n",
    "  target_train            = titanic_train['Survived'].values\n",
    "  target_test             = titanic_test ['Survived'].values\n",
    "    \n",
    "if not titanic:\n",
    "    # Fallback: Wir verwenden die Features aus dem Iris-Datensatz\n",
    "    print(\"Iris\")  \n",
    "    features_train_unscaled, features_test_unscaled, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# targets=y: eine einzige Spalte von zugehörigen Klassen 0, 1 oder 2\n",
    "y_train = pd.DataFrame(target_train)\n",
    "y_test = pd.DataFrame(target_test)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = scaler.fit_transform(features_train_unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1050.0</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.6</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>-0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1       2\n",
       "count  1050.0  1050.0  1050.0\n",
       "mean     -0.0     0.0    -0.0\n",
       "std       1.0     1.0     1.0\n",
       "min      -1.6    -2.9    -0.7\n",
       "25%      -0.4    -0.5    -0.7\n",
       "50%       0.8     0.2    -0.7\n",
       "75%       0.8     0.2     1.4\n",
       "max       0.8     3.6     1.4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train = scaler.fit_transform(features_train_unscaled)\n",
    "features_test  = scaler.transform(features_test_unscaled)\n",
    "\n",
    "# X: Features-Matrix, viele Zeilen von einzelnen Messungen\n",
    "X_train_unscaled = pd.DataFrame(features_train_unscaled)\n",
    "X_train = pd.DataFrame(features_train)\n",
    "X_test = pd.DataFrame(features_test)\n",
    "\n",
    "\n",
    "# X_train_unscaled.describe().round(1)\n",
    "# hat die Skalierung funktioniert?\n",
    "X_train.describe().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.551499</td>\n",
       "      <td>-1.424282</td>\n",
       "      <td>1.355669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.837173</td>\n",
       "      <td>0.031303</td>\n",
       "      <td>-0.737643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.357163</td>\n",
       "      <td>1.122991</td>\n",
       "      <td>1.355669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.551499</td>\n",
       "      <td>0.152298</td>\n",
       "      <td>-0.737643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.837173</td>\n",
       "      <td>0.152298</td>\n",
       "      <td>-0.737643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0 -1.551499 -1.424282  1.355669\n",
       "1  0.837173  0.031303 -0.737643\n",
       "2 -0.357163  1.122991  1.355669\n",
       "3 -1.551499  0.152298 -0.737643\n",
       "4  0.837173  0.152298 -0.737643"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn basiert auf Numpy, eigentlich ist kein Pandas erforderlich. Wir zeigen hier an einem Baseline-Classifier, wie man rein mit Sklearn einen Klassifizierer erstellt. Ein- und Ausgabe-Datenformat ist ein numpy.ndarray.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=1, strategy='uniform')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create (dummy) classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "dummy = DummyClassifier(strategy='uniform', random_state=1)\n",
    "\n",
    "# \"Train\" model\n",
    "dummy.fit(features_train, target_train)\n",
    "\n",
    "# unbekannte Exemplare klassifizieren: \n",
    "# Für jede Zeile in features_test wird eine Klasse errechnet. \n",
    "# Ergebnis ist ein Vektor.\n",
    "\n",
    "#print(dummy.score(features_test, target_test), dummy.predict(features_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Wranglig machen wir aber genau genommen mit Pandas. Also bekommt auch Sklearn Pandas-Objekte, also ein pd.DataFrame als Eingabe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=10, random_state=1)\n",
    "rfc.fit(X_train, y_train[0])\n",
    "#print(rfc.score(X_test, y_test[0]), rfc.predict(X_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=1000, class_weight=None, cv=3, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=1000,\n",
       "           multi_class='ovr', n_jobs=None, penalty='l2', random_state=None,\n",
       "           refit=True, scoring=None, solver='saga', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html\n",
    "from sklearn import linear_model\n",
    "logit = linear_model.LogisticRegressionCV(Cs=1000, cv=3, multi_class='ovr', solver='saga', max_iter=1000)\n",
    "logit.fit(X_train, y_train[0])\n",
    "#print(logit.score(X_test, y_test[0]), logit.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=1000,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='elasticnet',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "from sklearn import linear_model\n",
    "sgdEnet = linear_model.SGDClassifier(penalty='elasticnet', max_iter=1000, tol=1e-3)\n",
    "sgdEnet.fit(X_train, y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['logit']=pd.Series(logit.predict(X_test))\n",
    "y_test['rfc']= pd.Series(rfc.predict(X_test))\n",
    "y_test['sgdEnet']= pd.Series(sgdEnet.predict(X_test))\n",
    "y_test['dummy']=pd.Series(dummy.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy:\n",
      " 0.467680608365019 \n",
      " [[77 91]\n",
      " [49 46]]\n",
      "rfc:\n",
      " 0.8060836501901141 \n",
      " [[153  15]\n",
      " [ 36  59]]\n",
      "logit:\n",
      " 0.8212927756653993 \n",
      " [[161   7]\n",
      " [ 40  55]]\n",
      "sgdEnet:\n",
      " 0.7414448669201521 \n",
      " [[124  44]\n",
      " [ 24  71]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Get accuracy score\n",
    "print(\"dummy:\\n\", \n",
    "      dummy.score(X_test, y_test[0]), '\\n',\n",
    "      confusion_matrix(y_test[0], y_test['dummy']))\n",
    "print(\"rfc:\\n\", \n",
    "      rfc.score(X_test, y_test[0]), '\\n', \n",
    "     confusion_matrix(y_test[0], y_test['rfc']))\n",
    "print(\"logit:\\n\", \n",
    "      logit.score(X_test, y_test[0]), '\\n',\n",
    "     confusion_matrix(y_test[0], y_test['logit']))\n",
    "print(\"sgdEnet:\\n\", \n",
    "      sgdEnet.score(X_test, y_test[0]), '\\n',\n",
    "     confusion_matrix(y_test[0], y_test['sgdEnet']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86       168\n",
      "           1       0.80      0.62      0.70        95\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       263\n",
      "   macro avg       0.80      0.77      0.78       263\n",
      "weighted avg       0.81      0.81      0.80       263\n",
      "\n",
      "logit:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87       168\n",
      "           1       0.89      0.58      0.70        95\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       263\n",
      "   macro avg       0.84      0.77      0.79       263\n",
      "weighted avg       0.83      0.82      0.81       263\n",
      "\n",
      "sgdEnet:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.74      0.78       168\n",
      "           1       0.62      0.75      0.68        95\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       263\n",
      "   macro avg       0.73      0.74      0.73       263\n",
      "weighted avg       0.76      0.74      0.75       263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "# from sklearn.metrics import classification_report\n",
    "# y_true = [0, 1, 2, 2, 2]\n",
    "# y_pred = [0, 0, 2, 2, 1]\n",
    "# target_names = ['class 0', 'class 1', 'class 2']\n",
    "# print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n",
    "print(\"rfc:\\n\", classification_report(y_test[0].values, y_test['rfc'].values))\n",
    "print(\"logit:\\n\", classification_report(y_test[0].values, y_test['logit'].values))\n",
    "print(\"sgdEnet:\\n\", classification_report(y_test[0].values, y_test['sgdEnet'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown",
    "format_version": "1.0",
    "jupytext_version": "0.8.6"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
