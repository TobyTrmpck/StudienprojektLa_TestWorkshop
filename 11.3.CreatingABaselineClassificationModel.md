---
jupyter:
  jupytext:
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.0'
      jupytext_version: 0.8.6
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```python
import numpy as np
import pandas as pd

# Fallback-Option: Rechne über dem Iris-Datensatz. 
# Aber eigentlich interessiert uns ja Titanic:
titanic = True
```

Dieses Notebook: Kleine Ausarbeitung von MLPC Rezept 11.3. Datensatz laden, skalieren, Logit-Regression anwenden.

Zu tun: Alter besser berechnen als stur eine 33.33 einzutragen. Also eignet sich dieses Notebook als Umgebung, um ein kleines Regressions-Projekt zur Alters-Abschätzung einzufügen.


Datensätze laden
----


### Fallback: Iris

Ergebnis des Ladens ist ein ```numpy ndarray```


```python
# Load data 
from sklearn.datasets import load_iris
iris = load_iris()

# Create target vector and feature matrix
features, target = iris.data, iris.target

# Split into training and test set
from sklearn.model_selection import train_test_split

# Iris, mit np.ndarray
features_train_unscaled, features_test_unscaled, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)
type(features_train_unscaled)
```

### Titanic mit pd.read_csv laden

Ergebnis ist ein ```DataFrame```


```python
# url = 'https://tinyurl.com/titanic-csv'
url = 'https://raw.githubusercontent.com/chrisalbon/simulated_datasets/master/titanic.csv'
df = pd.read_csv(url).drop(['Sex', 'Name'], axis=1)

```

```python
df['PClassNum'] = df['PClass'].replace(["1st", "2nd", "3rd"], [1.,2.,3.])
# alternative Syntax:
# df['PClassNum'] = df['PClass'].replace({"1st":1, "2nd":2, "3rd":3, "*":2})
```

```python
# prüfen: gibt es noch Werte, die wir nicht ersetzt haben?
df.PClassNum.value_counts()

```

```python
# aha, in einer Reihe wurde ein "*" als Kennzeichen für NaN verwendet.
df['PClassNum'] = df['PClassNum'].replace(["*"], [2])
df.PClassNum.value_counts()
```

```python
# gaanz viele NaN im Attribut Alter!
# als baseline möge die Trivial-Strategie genügen (später besser machen)
df['Age'] = df['Age'].replace(np.nan, 33.33)  

```

```python
# Train-Test-Split Titanic
from sklearn.model_selection import train_test_split

# Titanic, mit DataFrame
titanic_train, titanic_test = train_test_split(df, test_size=0.2,  random_state=42)
titanic_train.head()
```

```python
if titanic:
  print("Titanic")  
  features_train_unscaled = titanic_train[['PClassNum', 'Age', 'SexCode']].values
  features_test_unscaled  = titanic_test [['PClassNum', 'Age', 'SexCode']].values
  target_train            = titanic_train['Survived'].values
  target_test             = titanic_test ['Survived'].values
    
if not titanic:
    # Fallback: Wir verwenden die Features aus dem Iris-Datensatz
    print("Iris")  
    features_train_unscaled, features_test_unscaled, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)
```

```python
import pandas as pd
# targets=y: eine einzige Spalte von zugehörigen Klassen 0, 1 oder 2
y_train = pd.DataFrame(target_train)
y_test = pd.DataFrame(target_test)

from sklearn import preprocessing
scaler = preprocessing.StandardScaler()
```

```python
features_train = scaler.fit_transform(features_train_unscaled)
```

```python
features_train = scaler.fit_transform(features_train_unscaled)
features_test  = scaler.transform(features_test_unscaled)

# X: Features-Matrix, viele Zeilen von einzelnen Messungen
X_train_unscaled = pd.DataFrame(features_train_unscaled)
X_train = pd.DataFrame(features_train)
X_test = pd.DataFrame(features_test)


# X_train_unscaled.describe().round(1)
# hat die Skalierung funktioniert?
X_train.describe().round(1)
```

```python
X_train.head()
```

Sklearn basiert auf Numpy, eigentlich ist kein Pandas erforderlich. Wir zeigen hier an einem Baseline-Classifier, wie man rein mit Sklearn einen Klassifizierer erstellt. Ein- und Ausgabe-Datenformat ist ein numpy.ndarray.



```python
# Create (dummy) classifier
from sklearn.dummy import DummyClassifier
dummy = DummyClassifier(strategy='uniform', random_state=1)

# "Train" model
dummy.fit(features_train, target_train)

# unbekannte Exemplare klassifizieren: 
# Für jede Zeile in features_test wird eine Klasse errechnet. 
# Ergebnis ist ein Vektor.

#print(dummy.score(features_test, target_test), dummy.predict(features_test))

```

Data Wranglig machen wir aber genau genommen mit Pandas. Also bekommt auch Sklearn Pandas-Objekte, also ein pd.DataFrame als Eingabe.

```python
from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(n_estimators=10, random_state=1)
rfc.fit(X_train, y_train[0])
#print(rfc.score(X_test, y_test[0]), rfc.predict(X_test) )
```

```python
# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html
from sklearn import linear_model
logit = linear_model.LogisticRegressionCV(Cs=1000, cv=3, multi_class='ovr', solver='saga', max_iter=1000)
logit.fit(X_train, y_train[0])
#print(logit.score(X_test, y_test[0]), logit.predict(X_test))
```

```python
# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html
from sklearn import linear_model
sgdEnet = linear_model.SGDClassifier(penalty='elasticnet', max_iter=1000, tol=1e-3)
sgdEnet.fit(X_train, y_train[0])

```

```python
y_test['logit']=pd.Series(logit.predict(X_test))
y_test['rfc']= pd.Series(rfc.predict(X_test))
y_test['sgdEnet']= pd.Series(sgdEnet.predict(X_test))
y_test['dummy']=pd.Series(dummy.predict(X_test))
```

```python
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score

# Get accuracy score
print("dummy:\n", 
      dummy.score(X_test, y_test[0]), '\n',
      confusion_matrix(y_test[0], y_test['dummy']))
print("rfc:\n", 
      rfc.score(X_test, y_test[0]), '\n', 
     confusion_matrix(y_test[0], y_test['rfc']))
print("logit:\n", 
      logit.score(X_test, y_test[0]), '\n',
     confusion_matrix(y_test[0], y_test['logit']))
print("sgdEnet:\n", 
      sgdEnet.score(X_test, y_test[0]), '\n',
     confusion_matrix(y_test[0], y_test['sgdEnet']))

```

```python
# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html
# from sklearn.metrics import classification_report
# y_true = [0, 1, 2, 2, 2]
# y_pred = [0, 0, 2, 2, 1]
# target_names = ['class 0', 'class 1', 'class 2']
# print(classification_report(y_true, y_pred, target_names=target_names))

print("rfc:\n", classification_report(y_test[0].values, y_test['rfc'].values))
print("logit:\n", classification_report(y_test[0].values, y_test['logit'].values))
print("sgdEnet:\n", classification_report(y_test[0].values, y_test['sgdEnet'].values))
```

```python

```

```python

```
